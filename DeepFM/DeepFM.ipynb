{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b826f17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gz\\miniconda3\\envs\\torch_gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import time, json, datetime \n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717219d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, cate_fea_nuniqs, nume_fea_size=0, emb_size=8, \n",
    "                 hid_dims=[256, 128], num_classes=1, dropout=[0.2, 0.2]): \n",
    "        \"\"\"\n",
    "        cate_fea_nuniqs: 类别特征的唯一值个数列表，也就是每个类别特征的vocab_size所组成的列表\n",
    "        nume_fea_size: 数值特征的个数，该模型会考虑到输入全为类别型，即没有数值特征的情况 \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cate_fea_size = len(cate_fea_nuniqs)\n",
    "        self.nume_fea_size = nume_fea_size\n",
    "        \n",
    "        \"\"\"FM部分\"\"\"\n",
    "        # 一阶\n",
    "        if self.nume_fea_size != 0:\n",
    "            self.fm_1st_order_dense = nn.Linear(self.nume_fea_size, 1)  # 数值特征的一阶表示\n",
    "        self.fm_1st_order_sparse_emb = nn.ModuleList([\n",
    "            nn.Embedding(voc_size, 1) for voc_size in cate_fea_nuniqs])  # 类别特征的一阶表示\n",
    "        \n",
    "        # 二阶\n",
    "        self.fm_2nd_order_sparse_emb = nn.ModuleList([\n",
    "            nn.Embedding(voc_size, emb_size) for voc_size in cate_fea_nuniqs])  # 类别特征的二阶表示\n",
    "        \n",
    "        \"\"\"DNN部分\"\"\"\n",
    "        self.all_dims = [self.cate_fea_size * emb_size] + hid_dims\n",
    "        self.dense_linear = nn.Linear(self.nume_fea_size, self.cate_fea_size * emb_size)  # 数值特征的维度变换到FM输出维度一致\n",
    "        self.relu = nn.ReLU()\n",
    "        # for DNN \n",
    "        for i in range(1, len(self.all_dims)):\n",
    "            setattr(self, 'linear_'+str(i), nn.Linear(self.all_dims[i-1], self.all_dims[i]))\n",
    "            setattr(self, 'batchNorm_' + str(i), nn.BatchNorm1d(self.all_dims[i]))\n",
    "            setattr(self, 'activation_' + str(i), nn.ReLU())\n",
    "            setattr(self, 'dropout_'+str(i), nn.Dropout(dropout[i-1]))\n",
    "        # for output \n",
    "        self.dnn_linear = nn.Linear(hid_dims[-1], num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X_sparse, X_dense=None):\n",
    "        \"\"\"\n",
    "        X_sparse: 类别型特征输入  [bs, cate_fea_size]\n",
    "        X_dense: 数值型特征输入（可能没有）  [bs, dense_fea_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"FM 一阶部分\"\"\"\n",
    "        fm_1st_sparse_res = [emb(X_sparse[:, i].unsqueeze(1)).view(-1, 1) \n",
    "                             for i, emb in enumerate(self.fm_1st_order_sparse_emb)]\n",
    "        fm_1st_sparse_res = torch.cat(fm_1st_sparse_res, dim=1)  # [bs, cate_fea_size]\n",
    "        fm_1st_sparse_res = torch.sum(fm_1st_sparse_res, 1,  keepdim=True)  # [bs, 1]\n",
    "        \n",
    "        if X_dense is not None:\n",
    "            fm_1st_dense_res = self.fm_1st_order_dense(X_dense) \n",
    "            fm_1st_part = fm_1st_sparse_res + fm_1st_dense_res\n",
    "        else:\n",
    "            fm_1st_part = fm_1st_sparse_res   # [bs, 1]\n",
    "        \n",
    "        \"\"\"FM 二阶部分\"\"\"\n",
    "        fm_2nd_order_res = [emb(X_sparse[:, i].unsqueeze(1)) for i, emb in enumerate(self.fm_2nd_order_sparse_emb)]\n",
    "        fm_2nd_concat_1d = torch.cat(fm_2nd_order_res, dim=1)  # [bs, n, emb_size]  n为类别型特征个数(cate_fea_size)\n",
    "        \n",
    "        # 先求和再平方\n",
    "        sum_embed = torch.sum(fm_2nd_concat_1d, 1)  # [bs, emb_size]\n",
    "        square_sum_embed = sum_embed * sum_embed    # [bs, emb_size]\n",
    "        # 先平方再求和\n",
    "        square_embed = fm_2nd_concat_1d * fm_2nd_concat_1d  # [bs, n, emb_size]\n",
    "        sum_square_embed = torch.sum(square_embed, 1)  # [bs, emb_size]\n",
    "        # 相减除以2 \n",
    "        sub = square_sum_embed - sum_square_embed  \n",
    "        sub = sub * 0.5   # [bs, emb_size]\n",
    "        \n",
    "        fm_2nd_part = torch.sum(sub, 1, keepdim=True)   # [bs, 1]\n",
    "        \n",
    "        \"\"\"DNN部分\"\"\"\n",
    "        dnn_out = torch.flatten(fm_2nd_concat_1d, 1)   # [bs, n * emb_size]\n",
    "        \n",
    "        if X_dense is not None:\n",
    "            dense_out = self.relu(self.dense_linear(X_dense))   # [bs, n * emb_size]\n",
    "            dnn_out = dnn_out + dense_out   # [bs, n * emb_size]\n",
    "        \n",
    "        for i in range(1, len(self.all_dims)):\n",
    "            dnn_out = getattr(self, 'linear_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'batchNorm_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'activation_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'dropout_' + str(i))(dnn_out)\n",
    "        \n",
    "        dnn_out = self.dnn_linear(dnn_out)   # [bs, 1]\n",
    "        out = fm_1st_part + fm_2nd_part + dnn_out   # [bs, 1]\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85ace07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:04<00:00,  5.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 80.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.126477</td>\n",
       "      <td>-0.192994</td>\n",
       "      <td>0.034824</td>\n",
       "      <td>0.348693</td>\n",
       "      <td>-0.271948</td>\n",
       "      <td>-0.178906</td>\n",
       "      <td>0.128171</td>\n",
       "      <td>-0.162472</td>\n",
       "      <td>-0.366616</td>\n",
       "      <td>1.134878</td>\n",
       "      <td>1.126624</td>\n",
       "      <td>-0.065908</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>103950</td>\n",
       "      <td>48164</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>3796</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>21865</td>\n",
       "      <td>1153</td>\n",
       "      <td>80900</td>\n",
       "      <td>1490</td>\n",
       "      <td>17</td>\n",
       "      <td>3238</td>\n",
       "      <td>16400</td>\n",
       "      <td>9</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43790</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.265558</td>\n",
       "      <td>-0.269791</td>\n",
       "      <td>-0.037431</td>\n",
       "      <td>-0.140858</td>\n",
       "      <td>-0.220993</td>\n",
       "      <td>-0.174621</td>\n",
       "      <td>1.157833</td>\n",
       "      <td>-0.162472</td>\n",
       "      <td>0.264282</td>\n",
       "      <td>-0.554643</td>\n",
       "      <td>2.349247</td>\n",
       "      <td>-0.065908</td>\n",
       "      <td>-0.050398</td>\n",
       "      <td>20</td>\n",
       "      <td>249</td>\n",
       "      <td>108293</td>\n",
       "      <td>58867</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>4961</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "      <td>15314</td>\n",
       "      <td>653</td>\n",
       "      <td>111841</td>\n",
       "      <td>2637</td>\n",
       "      <td>2</td>\n",
       "      <td>680</td>\n",
       "      <td>108006</td>\n",
       "      <td>9</td>\n",
       "      <td>3188</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>13014</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7205</td>\n",
       "      <td>54</td>\n",
       "      <td>16624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.265558</td>\n",
       "      <td>-0.263883</td>\n",
       "      <td>-0.014206</td>\n",
       "      <td>-0.263245</td>\n",
       "      <td>-0.205647</td>\n",
       "      <td>-0.163907</td>\n",
       "      <td>-0.215049</td>\n",
       "      <td>-0.263167</td>\n",
       "      <td>-0.424784</td>\n",
       "      <td>-0.554643</td>\n",
       "      <td>-0.299769</td>\n",
       "      <td>-0.065908</td>\n",
       "      <td>-0.076205</td>\n",
       "      <td>383</td>\n",
       "      <td>168</td>\n",
       "      <td>109278</td>\n",
       "      <td>43314</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>3938</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>9543</td>\n",
       "      <td>1653</td>\n",
       "      <td>140994</td>\n",
       "      <td>1664</td>\n",
       "      <td>2</td>\n",
       "      <td>6812</td>\n",
       "      <td>97195</td>\n",
       "      <td>0</td>\n",
       "      <td>1727</td>\n",
       "      <td>1037</td>\n",
       "      <td>2</td>\n",
       "      <td>73724</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7205</td>\n",
       "      <td>1</td>\n",
       "      <td>6343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.265558</td>\n",
       "      <td>-0.184132</td>\n",
       "      <td>-0.045172</td>\n",
       "      <td>-0.630409</td>\n",
       "      <td>-0.103523</td>\n",
       "      <td>-0.091052</td>\n",
       "      <td>-0.197888</td>\n",
       "      <td>-0.187645</td>\n",
       "      <td>-0.268178</td>\n",
       "      <td>-0.554643</td>\n",
       "      <td>-0.299769</td>\n",
       "      <td>-0.065908</td>\n",
       "      <td>-0.153627</td>\n",
       "      <td>760</td>\n",
       "      <td>312</td>\n",
       "      <td>84271</td>\n",
       "      <td>68069</td>\n",
       "      <td>160</td>\n",
       "      <td>6</td>\n",
       "      <td>9868</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>12169</td>\n",
       "      <td>165</td>\n",
       "      <td>39480</td>\n",
       "      <td>2762</td>\n",
       "      <td>5</td>\n",
       "      <td>1778</td>\n",
       "      <td>78532</td>\n",
       "      <td>0</td>\n",
       "      <td>1371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35768</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.151685</td>\n",
       "      <td>-0.269791</td>\n",
       "      <td>-0.042592</td>\n",
       "      <td>-0.385633</td>\n",
       "      <td>-0.257790</td>\n",
       "      <td>-0.146764</td>\n",
       "      <td>-0.197888</td>\n",
       "      <td>0.038919</td>\n",
       "      <td>-0.388988</td>\n",
       "      <td>1.134878</td>\n",
       "      <td>-0.299769</td>\n",
       "      <td>-0.065908</td>\n",
       "      <td>-0.102013</td>\n",
       "      <td>760</td>\n",
       "      <td>451</td>\n",
       "      <td>17999</td>\n",
       "      <td>16618</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>4309</td>\n",
       "      <td>410</td>\n",
       "      <td>2</td>\n",
       "      <td>5368</td>\n",
       "      <td>231</td>\n",
       "      <td>11597</td>\n",
       "      <td>738</td>\n",
       "      <td>2</td>\n",
       "      <td>768</td>\n",
       "      <td>105445</td>\n",
       "      <td>5</td>\n",
       "      <td>217</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>116420</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19260</td>\n",
       "      <td>36</td>\n",
       "      <td>4586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        I1        I2        I3        I4        I5        I6  \\\n",
       "0      1 -0.126477 -0.192994  0.034824  0.348693 -0.271948 -0.178906   \n",
       "1      0 -0.265558 -0.269791 -0.037431 -0.140858 -0.220993 -0.174621   \n",
       "2      0 -0.265558 -0.263883 -0.014206 -0.263245 -0.205647 -0.163907   \n",
       "3      0 -0.265558 -0.184132 -0.045172 -0.630409 -0.103523 -0.091052   \n",
       "4      0  0.151685 -0.269791 -0.042592 -0.385633 -0.257790 -0.146764   \n",
       "\n",
       "         I7        I8        I9       I10       I11       I12       I13   C1  \\\n",
       "0  0.128171 -0.162472 -0.366616  1.134878  1.126624 -0.065908  0.052830   20   \n",
       "1  1.157833 -0.162472  0.264282 -0.554643  2.349247 -0.065908 -0.050398   20   \n",
       "2 -0.215049 -0.263167 -0.424784 -0.554643 -0.299769 -0.065908 -0.076205  383   \n",
       "3 -0.197888 -0.187645 -0.268178 -0.554643 -0.299769 -0.065908 -0.153627  760   \n",
       "4 -0.197888  0.038919 -0.388988  1.134878 -0.299769 -0.065908 -0.102013  760   \n",
       "\n",
       "    C2      C3     C4   C5  C6    C7   C8  C9    C10   C11     C12   C13  C14  \\\n",
       "0   10  103950  48164   37   6  3796   18   2  21865  1153   80900  1490   17   \n",
       "1  249  108293  58867   37  13  4961  165   2  15314   653  111841  2637    2   \n",
       "2  168  109278  43314   37  13  3938   18   2   9543  1653  140994  1664    2   \n",
       "3  312   84271  68069  160   6  9868   18   2  12169   165   39480  2762    5   \n",
       "4  451   17999  16618   37   6  4309  410   2   5368   231   11597   738    2   \n",
       "\n",
       "    C15     C16  C17   C18   C19  C20     C21  C22  C23    C24  C25    C26  \n",
       "0  3238   16400    9  1541     0    0   43790    0    4  25283    0      0  \n",
       "1   680  108006    9  3188   212    2   13014    0    4   7205   54  16624  \n",
       "2  6812   97195    0  1727  1037    2   73724    0    2   7205    1   6343  \n",
       "3  1778   78532    0  1371     0    0   35768    0    3  15271    0      0  \n",
       "4   768  105445    5   217   242    2  116420    0    2  19260   36   4586  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"criteo_sample_50w.csv\")\n",
    "\n",
    "dense_features = [f for f in data.columns.tolist() if f[0] == \"I\"]\n",
    "sparse_features = [f for f in data.columns.tolist() if f[0] == \"C\"]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-10086', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']\n",
    "\n",
    "## 类别特征labelencoder\n",
    "for feat in tqdm(sparse_features):\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "\n",
    "## 数值特征标准化\n",
    "for feat in tqdm(dense_features):\n",
    "    mean = data[feat].mean()\n",
    "    std = data[feat].std()\n",
    "    data[feat] = (data[feat] - mean) / (std + 1e-12)   # 防止除零\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2fb5cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 40) (100000, 40)\n",
      "cuda\n",
      "{'Total': 7037251, 'Trainable': 7037251}\n"
     ]
    }
   ],
   "source": [
    "train, valid = train_test_split(data, test_size=0.2, random_state=2020)\n",
    "print(train.shape, valid.shape)\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.LongTensor(train[sparse_features].values), \n",
    "                                   torch.FloatTensor(train[dense_features].values),\n",
    "                                   torch.FloatTensor(train['label'].values),)\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=2048, shuffle=True)\n",
    "\n",
    "valid_dataset = Data.TensorDataset(torch.LongTensor(valid[sparse_features].values), \n",
    "                                   torch.FloatTensor(valid[dense_features].values),\n",
    "                                   torch.FloatTensor(valid['label'].values),)\n",
    "valid_loader = Data.DataLoader(dataset=valid_dataset, batch_size=4096, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "cate_fea_nuniqs = [data[f].nunique() for f in sparse_features]\n",
    "model = DeepFM(cate_fea_nuniqs, nume_fea_size=len(dense_features))\n",
    "model.to(device)\n",
    "loss_fcn = nn.BCELoss()  # Loss函数\n",
    "loss_fcn = loss_fcn.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001) \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "\n",
    "# 打印模型参数\n",
    "def get_parameter_number(model):\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "print(get_parameter_number(model))\n",
    "\n",
    "# 定义日志（data文件夹下，同级目录新建一个data文件夹）\n",
    "def write_log(w):\n",
    "    file_name = 'data/' + datetime.date.today().strftime('%m%d')+\"_{}.log\".format(\"deepfm\")\n",
    "    t0 = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "    info = \"{} : {}\".format(t0, w)\n",
    "    print(info)\n",
    "    with open(file_name, 'a') as f: \n",
    "        f.write(info + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr : 0.005\n",
      "23:49:12 : Epoch: 1\n",
      "23:49:20 : Epoch 0001 | Step 0050 / 196 | Loss 20.0687 | Time 7.4413\n",
      "23:49:22 : Epoch 0001 | Step 0100 / 196 | Loss 17.0355 | Time 10.0178\n",
      "23:49:25 : Epoch 0001 | Step 0150 / 196 | Loss 14.7216 | Time 12.3736\n",
      "23:49:27 : Epoch 0001 | Step 0196 / 196 | Loss 12.6788 | Time 14.3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:01, 19.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:49:28 : Current AUC: 0.668199, Best AUC: 0.668199\n",
      "\n",
      "Current lr : 0.004\n",
      "23:49:28 : Epoch: 2\n",
      "23:49:30 : Epoch 0002 | Step 0050 / 196 | Loss 3.0824 | Time 2.1991\n",
      "23:49:32 : Epoch 0002 | Step 0100 / 196 | Loss 2.4526 | Time 4.2070\n",
      "23:49:34 : Epoch 0002 | Step 0150 / 196 | Loss 2.0562 | Time 6.2776\n",
      "23:49:36 : Epoch 0002 | Step 0196 / 196 | Loss 1.8110 | Time 8.1431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:01, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:49:38 : Current AUC: 0.675466, Best AUC: 0.675466\n",
      "\n",
      "Current lr : 0.0032\n",
      "23:49:38 : Epoch: 3\n",
      "23:49:40 : Epoch 0003 | Step 0050 / 196 | Loss 0.8072 | Time 2.3218\n",
      "23:49:42 : Epoch 0003 | Step 0100 / 196 | Loss 0.7716 | Time 4.3369\n",
      "23:49:44 : Epoch 0003 | Step 0150 / 196 | Loss 0.7426 | Time 6.5938\n",
      "23:49:46 : Epoch 0003 | Step 0196 / 196 | Loss 0.7185 | Time 8.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:01, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:49:48 : Current AUC: 0.702935, Best AUC: 0.702935\n",
      "\n",
      "Current lr : 0.00256\n",
      "23:49:48 : Epoch: 4\n",
      "23:49:50 : Epoch 0004 | Step 0050 / 196 | Loss 0.5870 | Time 2.3064\n",
      "23:49:52 : Epoch 0004 | Step 0100 / 196 | Loss 0.5759 | Time 4.3373\n",
      "23:49:54 : Epoch 0004 | Step 0150 / 196 | Loss 0.5675 | Time 6.5791\n",
      "23:49:56 : Epoch 0004 | Step 0196 / 196 | Loss 0.5626 | Time 8.4781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:01, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:49:57 : Current AUC: 0.727698, Best AUC: 0.727698\n",
      "\n",
      "Current lr : 0.0020480000000000003\n",
      "23:49:57 : Epoch: 5\n"
     ]
    }
   ],
   "source": [
    "def train_and_eval(model, train_loader, valid_loader, epochs, device):\n",
    "    best_auc = 0.0\n",
    "    for _ in range(epochs):\n",
    "        \"\"\"训练部分\"\"\"\n",
    "        model.train()\n",
    "        print(\"Current lr : {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        write_log('Epoch: {}'.format(_ + 1))\n",
    "        train_loss_sum = 0.0\n",
    "        start_time = time.time()\n",
    "        for idx, x in enumerate(train_loader):\n",
    "            cate_fea, nume_fea, label = x[0], x[1], x[2]\n",
    "            cate_fea, nume_fea, label = cate_fea.to(device), nume_fea.to(device), label.float().to(device)\n",
    "            pred = model(cate_fea, nume_fea).view(-1)\n",
    "            loss = loss_fcn(pred, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_sum += loss.cpu().item()\n",
    "            if (idx+1) % 50 == 0 or (idx + 1) == len(train_loader):\n",
    "                write_log(\"Epoch {:04d} | Step {:04d} / {} | Loss {:.4f} | Time {:.4f}\".format(\n",
    "                          _+1, idx+1, len(train_loader), train_loss_sum/(idx+1), time.time() - start_time))\n",
    "        scheduler.step()\n",
    "        \"\"\"推断部分\"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_labels, valid_preds = [], []\n",
    "            for idx, x in tqdm(enumerate(valid_loader)):\n",
    "                cate_fea, nume_fea, label = x[0], x[1], x[2]\n",
    "                cate_fea, nume_fea = cate_fea.to(device), nume_fea.to(device)\n",
    "                pred = model(cate_fea, nume_fea).reshape(-1).data.cpu().numpy().tolist()\n",
    "                valid_preds.extend(pred)\n",
    "                valid_labels.extend(label.cpu().numpy().tolist())\n",
    "        cur_auc = roc_auc_score(valid_labels, valid_preds)\n",
    "        if cur_auc > best_auc:\n",
    "            best_auc = cur_auc\n",
    "            torch.save(model.state_dict(), \"data/deepfm_best.pth\")\n",
    "        write_log('Current AUC: %.6f, Best AUC: %.6f\\n' % (cur_auc, best_auc))\n",
    "        \n",
    "\n",
    "train_and_eval(model, train_loader, valid_loader, 30, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb33ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_gpu]",
   "language": "python",
   "name": "conda-env-torch_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
